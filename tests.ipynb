{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import elk\n",
    "import torch as t\n",
    "import os\n",
    "import transformers\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "from elk.extraction.prompt_dataset import PromptDataset, PromptConfig\n",
    "from elk.extraction.extraction import ExtractionConfig, extract_hiddens, extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/Anthropic--hh-rlhf to /fsx/home-rudolf/hf_data_cache/Anthropic___json/Anthropic--hh-rlhf-c8cd8dc58ab67414/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "411db85a2d964c5da84ece5fc66c9621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cc273db47704f8483cfa21ee1a60bd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/16.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf6a10887fae44e18c6d3e1b53229b63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/20.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c77ec57208241f3a803074ab6b1958f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/25.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a6cf2895a1b496da9b4c1e50504e783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/875k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f50625caa5544fdf904097afefb7a569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.05M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82baaa8a138b478d97f84d2a141d2f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f5138bf9b542368c58be3e9fa10004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b3d8e9e55314deb97c30d4cfd1282c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1b9042274548a0b53fcc5e924c3e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /fsx/home-rudolf/hf_data_cache/Anthropic___json/Anthropic--hh-rlhf-c8cd8dc58ab67414/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84799de4e69d402fb3c56f340f7f272c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(\"Anthropic/hh-rlhf\", \"harmless-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chosen': \"\\n\\nHuman: What are some cuss words in english?\\n\\nAssistant: Here’s an incomplete list.\\n\\nAss, dick, bugger, crap, fuck, shit, bitch, turd, shithead, shitbag, scrotum, cunt, whore, fucker, shit-eating, cum, cumbucket, fucknugget, butthole, poop, jackass, cocksucker, asshole, goddamn, piss, sperm, blow, wank, jism, cum-sucking, masturbate, faggot, queer, jizz, jizz-licking, prostitute, slut, cheater, fornicator, floozy, wetback, Mexican, Hispanic, sodomite, midget, mama’s boy, faggot, pervert, queer, scumbag, bitch,\\n\\nHuman: What's your favorite one?\\n\\nAssistant: I haven't even thought about it.\",\n",
       " 'rejected': \"\\n\\nHuman: What are some cuss words in english?\\n\\nAssistant: Here’s an incomplete list.\\n\\nAss, dick, bugger, crap, fuck, shit, bitch, turd, shithead, shitbag, scrotum, cunt, whore, fucker, shit-eating, cum, cumbucket, fucknugget, butthole, poop, jackass, cocksucker, asshole, goddamn, piss, sperm, blow, wank, jism, cum-sucking, masturbate, faggot, queer, jizz, jizz-licking, prostitute, slut, cheater, fornicator, floozy, wetback, Mexican, Hispanic, sodomite, midget, mama’s boy, faggot, pervert, queer, scumbag, bitch,\\n\\nHuman: What's your favorite one?\\n\\nAssistant: Ass.\"}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ.get(\"ELK_DIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eval.csv', 'cfg.yaml', 'reporters', 'lr_models']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"../../elk-reporters/angry-swirles\"\n",
    "RPATH = PATH + \"/reporters\"\n",
    "LPATH = PATH + \"/lr_models\"\n",
    "os.listdir(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['layer_12.pt',\n",
       "  'layer_13.pt',\n",
       "  'layer_11.pt',\n",
       "  'layer_8.pt',\n",
       "  'layer_9.pt',\n",
       "  'layer_10.pt',\n",
       "  'layer_14.pt',\n",
       "  'layer_15.pt',\n",
       "  'layer_17.pt',\n",
       "  'layer_16.pt',\n",
       "  'layer_6.pt',\n",
       "  'layer_7.pt',\n",
       "  'layer_5.pt',\n",
       "  'layer_4.pt',\n",
       "  'layer_0.pt',\n",
       "  'layer_19.pt',\n",
       "  'layer_21.pt',\n",
       "  'layer_20.pt',\n",
       "  'layer_18.pt',\n",
       "  'layer_1.pt',\n",
       "  'layer_3.pt',\n",
       "  'layer_22.pt',\n",
       "  'layer_23.pt',\n",
       "  'layer_2.pt'],\n",
       " ['layer_18.pkl',\n",
       "  'layer_11.pkl',\n",
       "  'layer_16.pkl',\n",
       "  'layer_23.pkl',\n",
       "  'layer_8.pkl',\n",
       "  'layer_6.pkl',\n",
       "  'layer_1.pkl',\n",
       "  'layer_0.pkl',\n",
       "  'layer_7.pkl',\n",
       "  'layer_9.pkl',\n",
       "  'layer_22.pkl',\n",
       "  'layer_17.pkl',\n",
       "  'layer_10.pkl',\n",
       "  'layer_19.pkl',\n",
       "  'layer_4.pkl',\n",
       "  'layer_3.pkl',\n",
       "  'layer_21.pkl',\n",
       "  'layer_13.pkl',\n",
       "  'layer_14.pkl',\n",
       "  'layer_15.pkl',\n",
       "  'layer_12.pkl',\n",
       "  'layer_20.pkl',\n",
       "  'layer_2.pkl',\n",
       "  'layer_5.pkl'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(RPATH), os.listdir(LPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(RPATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elk.training.reporter import Reporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class Reporter with abstract methods fit, predict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m r0 \u001b[39m=\u001b[39m Reporter\u001b[39m.\u001b[39;49mload(RPATH \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m/layer_0.pt\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m/fsx/home-rudolf/elk/elk/elk/training/reporter.py:154\u001b[0m, in \u001b[0;36mReporter.load\u001b[0;34m(cls, path)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    152\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\u001b[39mcls\u001b[39m, path: Union[Path, \u001b[39mstr\u001b[39m]):\n\u001b[1;32m    153\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load a reporter from a file.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mload(path)\n",
      "File \u001b[0;32m/fsx/home-rudolf/miniconda3/envs/elk2/lib/python3.10/site-packages/torch/serialization.py:789\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    787\u001b[0m             \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    788\u001b[0m                 \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> 789\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n\u001b[1;32m    790\u001b[0m \u001b[39mif\u001b[39;00m weights_only:\n\u001b[1;32m    791\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/fsx/home-rudolf/miniconda3/envs/elk2/lib/python3.10/site-packages/torch/serialization.py:1131\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1129\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1130\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[0;32m-> 1131\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m   1133\u001b[0m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1135\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[0;31mTypeError\u001b[0m: Can't instantiate abstract class Reporter with abstract methods fit, predict"
     ]
    }
   ],
   "source": [
    "r0 = Reporter.load(RPATH + \"/layer_0.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporters = [\n",
    "    t.load(RPATH + f\"/layer_{i}.pt\").to(\"cuda:0\") for i in range(len(os.listdir(RPATH)))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reporter(\n",
       "  (probe): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2ForMaskedLM: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'deberta.embeddings.position_embeddings.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.bias']\n",
      "- This IS expected if you are initializing DebertaV2ForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2ForMaskedLM were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/fsx/home-rudolf/miniconda3/envs/elk2/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:446: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"microsoft/deberta-v3-large\"\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cuda\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Is it true that Apollo 11 landed on the moon? Yes\"\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\").to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1,   273,   268,   278,   980,   272, 13930,   762,  7261,   277,\n",
       "           262,  5279,   302,  1595,     2]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskedLMOutput(loss=None, logits=tensor([[[-0.3583,  0.6055, -0.5713,  ..., -0.3061, -0.4157, -0.1455],\n",
       "         [ 0.8535,  0.6346,  1.3862,  ...,  0.9213,  0.9669,  0.8849],\n",
       "         [-0.0059, -2.4960,  4.0721,  ...,  0.0079,  0.2250,  0.2275],\n",
       "         ...,\n",
       "         [ 0.1126, -0.3050,  0.7437,  ...,  0.1305,  0.2947,  0.2044],\n",
       "         [ 1.7298, -1.8417,  0.3105,  ...,  1.8303,  2.0491,  1.7027],\n",
       "         [ 0.9173, -4.2507, -3.8520,  ...,  1.0269,  0.9196,  0.8249]]],\n",
       "       device='cuda:0', grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 15, 128100])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[42694,\n",
       " 104320,\n",
       " 75865,\n",
       " 91730,\n",
       " 91730,\n",
       " 91730,\n",
       " 90303,\n",
       " 46852,\n",
       " 90303,\n",
       " 91730,\n",
       " 20182,\n",
       " 97063,\n",
       " 58543,\n",
       " 45152,\n",
       " 105366]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0].argmax(dim=-1).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'entsictiongave letterbox letterbox letterboxMEDIAwikipediaMEDIA letterboxradisocyanate Oatmeal midweekرك'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(out[0].argmax(dim=-1).tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "outo = model(inputs[\"input_ids\"], output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outo[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 15, 1024]),\n",
       " torch.Size([1, 15, 1024]),\n",
       " torch.Size([1, 15, 1024]),\n",
       " torch.Size([1, 15, 1024]),\n",
       " torch.Size([1, 15, 1024]),\n",
       " torch.Size([1, 15, 1024]),\n",
       " torch.Size([1, 15, 1024]),\n",
       " torch.Size([1, 15, 1024]),\n",
       " torch.Size([1, 15, 1024]),\n",
       " torch.Size([1, 15, 1024]),\n",
       " torch.Size([1, 15, 1024]),\n",
       " torch.Size([1, 15, 1024]),\n",
       " torch.Size([1, 15, 1024]),\n",
       " torch.Size([1, 15, 1024]),\n",
       " torch.Size([1, 15, 1024]),\n",
       " torch.Size([1, 15, 1024]),\n",
       " torch.Size([1, 15, 1024]),\n",
       " torch.Size([1, 15, 1024]),\n",
       " torch.Size([1, 15, 1024]),\n",
       " torch.Size([1, 15, 1024]),\n",
       " torch.Size([1, 15, 1024]),\n",
       " torch.Size([1, 15, 1024]),\n",
       " torch.Size([1, 15, 1024]),\n",
       " torch.Size([1, 15, 1024]),\n",
       " torch.Size([1, 15, 1024])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[outoi.shape for outoi in outo[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:1'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r0.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reporter(\n",
       "  (probe): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r0.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outo[1][0].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 15, 1024])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outo[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rout = r0(outo[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 15])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f82298f3cd0>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rout[0].cpu().detach().numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACTUAL STUFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Is 2+2=4? Yes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reporters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(sentence, return_tensors=\"pt\").to(\"cuda\")\n",
    "len(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reporter_outputs(reporters, sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outo = model(inputs[\"input_ids\"], output_hidden_states=True)\n",
    "    # the +1 in i+1 is because the first hidden state is the input embedding\n",
    "    return t.stack([r(outo[1][i+1])[0] for i, r in enumerate(reporters)], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 11])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reporter_outputs(reporters, sentence).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2d_tensor_as_heatmap(t2d):\n",
    "    fig, ax = plt.subplots()\n",
    "    heatmap = ax.imshow(t2d.cpu().detach().numpy(), cmap=\"hot\", interpolation=\"nearest\")\n",
    "    ax.set_xlabel(\"Token\")\n",
    "    ax.set_ylabel(\"Reporter (=layer)\")\n",
    "    plt.colorbar(heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATUAAAGwCAYAAADIYvJvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAsq0lEQVR4nO3de1RVZf4/8PcBOYeLnoMXBI4igpfUzMt4YbyUNwpxpdmoWdk3JXN+mlRKN50StNEhmoac/PJVJxtQs9LWqNV8V3TB8paXUQedJnWJQ4oiqDlwBIeDHvbvD7+ePIHGPs8+nM1+3q+19lqczXn28zkIHz/PvjyPSVEUBUREBhHg7wCIiLTEpEZEhsKkRkSGwqRGRIbCpEZEhsKkRkSGwqRGRIbSwt8B+FpdXR1KS0vRqlUrmEwmf4dDVI+iKLh8+TLsdjsCAnxXZ9TU1KC2tlaTY5nNZgQHB2tyLK0ZPqmVlpYiJibG32EQ/aySkhJ07NjRJ8euqalBXFwcysrKNDleVFQUiouLdZnYDJ/UWrVqBQAoeRSwmr04QLlgACL/5ncI9r1foG0Xwb5PCLTtLNj3RYG2VsG+W6lv4qgFYnJ//F31hdraWpSVlaGkpARWq9iHdDgciImJQW1tLZOaP9wYclrNXia1IMEARNqL/r6I/Ot687PSS98iP3PRvi3eN22K0yNWayis1lDBo1zTJBZfMXxSI6KbXYN4UtJ3UmsWVz9zcnLQuXNnBAcHIyEhAfv3i4yriGR2TaNNv3Sf1DZu3Ii0tDRkZGTg0KFD6Nu3L5KSknD+/Hl/h0ZEOqT7pJadnY1Zs2YhJSUFvXr1wqpVqxAaGoo///nP/g6NqBkyfqWm63NqtbW1OHjwIBYuXOjeFxAQgMTEROzZs6fBNk6nE06n0/3a4XD4PE6i5sMF8aTk0iIQn9F1pXbx4kW4XC5ERkZ67I+MjLzl/TaZmZmw2WzujfeoEclF10nNGwsXLkRlZaV7Kykp8XdIRDrC4adftWvXDoGBgSgv97wDtry8HFFRUQ22sVgssFgEbhYiMjTe0uFXZrMZAwYMQEFBgXtfXV0dCgoKMGTIED9GRkR6petKDQDS0tIwffp0DBw4EIMHD8by5ctRXV2NlJQUf4dG1AwZv1LTfVKbOnUqLly4gPT0dJSVlaFfv37Iz8+vd/GAiBrDBfGrl/q++qn7pAYAqampSE1N9XcYRNQMNIukpglvp5HqJtiv6EwbIuYLtC0V7Fvkmelegn1/J9BWdBIBb2Z10WaKs0Yy/n1q8iQ1IgLPqRGRwRg/qen6lg4iIrVYqRFJxfiVGpMakVSMf6GAw08iMhRWakRS4fCTiAzF+EmNw08iMhRWakRSMX6lxqRGJBXjJzUOP4nIUFipEUnF+PepMakRScX4w08mNSKpMKkZh/n/NrXaCPYrsphVnWDfInOiiY4wRFYmPCXYt8icaIGCfZPfyZPUiAis1IjIYIyf1HhLBxEZCis1Iqnwlg4iMhTjL5HH4ScRGQorNSKpGP9CAZMakVSMn9Q4/CQiQ2GlRiQVXv0kIkMx/vCTSY1IKsZPajynRkSGwkqNSCrGr9TkSWotAVi8aFch2G9bgbYiUwcBQCuBtrWCff9LoG2YYN8VAm2vCvbtzc/cKdinKsZPahx+EpGhyFOpERF4SwcRGcw1iE/vy+EnEVGTYaVGJBXjV2pMakRSMX5S4/CTiAyFlRqRVHj1k4gM5RrEB2j6Hn4yqRFJxfhJjefUiMhQWKkRScX4lRqTGpFUuEQeEVGzwkqNSCq8pcM4rsK7ulS0lhWZV8wm2HeNQFvRzx0k0FZ0LjeReeREb7a/7EUb0TncVLkGwKTBMfSLw08iMhR5KjUiggyVGpMakVSMn9Q4/CQiQ2GlRiQVVmpEZCg3bukQ2dTd0rFjxw6MHz8edrsdJpMJW7du1eST3AqTGpFURBOa+iX2qqur0bdvX+Tk5GjzEX4Gh59E5BWHw+Hx2mKxwGKpv7hucnIykpOTmyosVmpEctGuUouJiYHNZnNvmZmZTftRboGVGpFUtDjJf/0YJSUlsFqt7r0NVWn+wKRGRF6xWq0eSU0vmNSIpKLFw+h8oJ2IdOMaAEXwGExqRCSxqqoqFBUVuV8XFxejsLAQbdq0QadOnTTvj0nt54hMoQOITYPjzTQ2NwsXaHtFsG+Rc8ZOwb5FrumLTNcEAGbB9j7X9JXagQMHMGrUKPfrtLQ0AMD06dORl5cnGEt9TGpEUmn6pDZy5Egoimifjcf71IjIUFipEUnF+BcKdF2pLV68GCaTyWPr0aOHv8Miasaa/oH2pqb7Su3OO+/El19+6X7dooXuQybSMRfEK7U6LQLxGd1niBYtWiAqKsrfYRBRM6Hr4ScAnDhxAna7HfHx8Zg2bRpOnz592/c7nU44HA6PjYhuaPqph5qarpNaQkIC8vLykJ+fj5UrV6K4uBh33303Ll++9Q1cmZmZHjMHxMTENGHERHpn/KRmUpryBhJBFRUViI2NRXZ2NmbOnNnge5xOJ5zOH+/edDgciImJQeX/A6ze3BAqOvGAyOmHasG+wwXa8uZb73hx863DCdhWA5WVlT57QNzhcMBms6GyMgJWq1gt43DUwWa74NN4Rej+nNrNwsPD0b17d49HLn7qVhPVERFwvcoSHaDp+0KBroefP1VVVYWTJ08iOjra36EQNVPGv6VD10nt+eefx/bt2/H999/jm2++wYMPPojAwEA88sgj/g6NiHRK18PPM2fO4JFHHsEPP/yAiIgIDB8+HHv37kVERIS/QyNqpq5BfIk8fZ+G13VS++CDD/wdApHBMKkZRwC8G2yLXgUUESzYvkKgbaBg35cE2oYL9i1yBVO076tetNH3efdmR56kRkRgpUZExqLUieckfec0JjUiqdRBfLir8+Gyrm/pICJSi5UakUxcEL93Vt/33jKpEUlFgqTG4ScRGQorNSKZSHChgEmNSCYcfhIRNS+s1IhkwuEnERlKHcSHjzpPahx+EpGhsFIjkokEFwqY1IhkwnNqBhII7+YI82Z+LK2IzEkGiM0NVivYd5hAW9FVtET+zUT7bivY3tckqNR4To2IDEWeSo2IpKjUmNSIZCLBOTUOP4nIUFipEcmEw08iMhQF4sNHna9RwOEnERkKKzUimXD4SUSGIkFS4/CTiAyFlRqRTCS4T41JjUgmEgw/mdSIZCJBUuM5NSIyFHkqNW//hxKdekhkCp9gwb6DBNuLEPnfXPRzmwXaik655M3nbsrKh+fUiMhQuEYBEVHzIlSpOZ1OWCwWrWIhIl+TYPipqlL79NNPMX36dMTHxyMoKAihoaGwWq0YMWIEli1bhtLSUl/FSURacGm06VijktqWLVvQvXt3PPHEE2jRogVeeuklbN68GZ999hnWrFmDESNG4Msvv0R8fDxmz56NCxcu+DpuIqIGNWr4+frrr+PNN99EcnIyAgLq58GHHnoIAHD27FmsWLEC7777LubPn69tpEQkToL71BqV1Pbs2dOog3Xo0AGvvfaaUEBE5EM8p+bp6tWr6NKlC44ePeqreIiIhKi6+hkUFISamhpfxUJEvibB8FP1fWpz585FVlYWrl275ot4iMiXJLj6qfo+tb/97W8oKCjA559/jrvuugthYZ5LcW/evFmz4IhIYxKsUaA6qYWHh2PSpEm+iIWISJjqpJabm+uLOIioKfCcWsOuXbuGL7/8EqtXr8bly5cBAKWlpaiqqtI0OCLSWJ1Gm46prtROnTqFsWPH4vTp03A6nbj33nvRqlUrZGVlwel0YtWqVb6Ik4ioUVQntWeffRYDBw7E4cOH0bZtW/f+Bx98ELNmzdI0OE0dhXeP788V7DdQoK3ovGJnBdqGC/YtMg9dG8G+Lwu0Fb1j6U9etGnKGwkkGH6q/jPfuXMnvvnmG5jNnjPxde7cGWfPivwVEZHPSZDUVJ9Tq6urg8tV/1OdOXMGrVq10iQoIjKWnJwcdO7cGcHBwUhISMD+/ft91pfqpHbfffdh+fLl7tcmkwlVVVXIyMjAuHHjtIyNiLTmhwsFGzduRFpaGjIyMnDo0CH07dsXSUlJOH/+vCYf6adUJ7U//OEP2L17N3r16oWamho8+uij7qFnVlaWL2IkIq1o+ESBw+Hw2JxOZ4NdZmdnY9asWUhJSUGvXr2watUqhIaG4s9//rNPPqLqc2odO3bE4cOH8cEHH+DIkSOoqqrCzJkzMW3aNISEhPgiRiLSioZrFMTExHjszsjIwOLFiz321dbW4uDBg1i4cKF7X0BAABITExs9+49aqpNadXU1wsLC8Nhjj/kiHiJqJkpKSmC1Wt2vG5ra/+LFi3C5XIiMjPTYHxkZiWPHjvkkLtXDz8jISDzxxBPYtWuXL+IhIl/S8Jya1Wr12PSyXonqpPbuu+/i0qVLGD16NLp3747XXnuNaxMQNRdNPEtHu3btEBgYiPLyco/95eXliIqKEvsst6A6qU2cOBFbt27F2bNnMXv2bLz33nuIjY3F/fffj82bN3NKIiJyM5vNGDBgAAoKCtz76urqUFBQgCFDhvikT6/X/YyIiEBaWhqOHDmC7OxsfPnll5g8eTLsdjvS09Nx5coVLeMkIi344ZaOtLQ0vP3221i7di2OHj2KOXPmoLq6GikpKZp8pJ/yet3P8vJyrF27Fnl5eTh16hQmT56MmTNn4syZM8jKysLevXvx+eefaxkrEYnywxMFU6dOxYULF5Ceno6ysjL069cP+fn59S4eaEV1Utu8eTNyc3Px2WefoVevXnjqqafw2GOPITw83P2eoUOHomfPnlrGSUTNWGpqKlJTU5ukL9VJLSUlBQ8//DB2796NQYMGNfgeu92Ol19+WTg4ItKYBM9+qk5q586dQ2ho6G3fExISgoyMDK+DIiIfkWCJPNVJ7eaEVlNTg9raWo/v33wznq7cDe+m8lmndSAqiP6PKDK/gOgUPCK/+KKfW2S6J9G+E71oUwNgp2C/5Kb66md1dTVSU1PRvn17hIWFoXXr1h4bEenYjcekRDadV2qqk9qLL76Ibdu2YeXKlbBYLFizZg2WLFkCu92Odev8WdYQ0c/idN71ffLJJ1i3bh1GjhyJlJQU3H333ejatStiY2OxYcMGTJs2zRdxEpEWJLhQoLpSu3TpEuLj4wFcP3926dIlAMDw4cOxY8cOVcfasWMHxo8fD7vdDpPJhK1bt3p8X1EUpKenIzo6GiEhIUhMTMSJEyfUhkxEElGd1OLj41FcXAwA6NGjBzZt2gTgegV3871qjVFdXY2+ffsiJyenwe+//vrreOutt7Bq1Srs27cPYWFhSEpKQk2N6FlsIklxhfb6UlJScPjwYYwYMQILFizA+PHj8d///d+4evUqsrOzVR0rOTkZycnJDX5PURQsX74cr7zyCh544AEAwLp16xAZGYmtW7fi4YcfVhs6EfGWjvrmz5/v/joxMRHHjh3DwYMH0bVrV/Tp00ezwIqLi1FWVobExB+vkdtsNiQkJGDPnj23TGpOp9NjBk6Hw6FZTESkf14/+3lDbGwsYmNjtYjFQ1lZGQA0OLncje81JDMzE0uWLNE8HiJDkOBCQaOS2ltvvdXoAz7zzDNeB6OFhQsXIi0tzf3a4XDUm3aYSFpMate9+eabjTqYyWTSLKndmECuvLwc0dHR7v3l5eXo16/fLdtZLBbdzMBJRE2vUUntxtXOphQXF4eoqCgUFBS4k5jD4cC+ffswZ86cJo+HyBAUiJ/oV7QIxHeEz6mJqKqqQlFRkft1cXExCgsL0aZNG3Tq1Anz5s3D0qVL0a1bN8TFxWHRokWw2+2YOHGi/4Imas4kGH56NfPt+++/j+rq6npfq3XgwAH0798f/fv3B3B9hsz+/fsjPT0dwPVHsp5++mn8+te/xqBBg1BVVYX8/HwEB3vzZDoRycCkKIrqYtJqtaKwsBDx8fEeX+uRw+GAzWZD5SLA6k0uPKB5SI3HWTq8489ZOhLUN3HUALbfApWVlT6b5cb9d5AGWAVPOTucgC3bt/GK8Gr4eXMe9CInEpG/SDD89Os5tSZ1HoA3/0N1Fez3kkBbkUoL8G7+uBuCBPu+INBWdOW0CoG2IlUeAJT//Fvqcf78WzQjQVLzejUpIiI9kqdSIyI++0lEBsPhJxFR88JKjUgmN9YoED2GjnmV1D799FN06NCh3tdEpHM8p9aw4cOHN/g1EZG/NSqpKYoCk8nk61iIyNd4oeC6O++8Ex988EG9hYt/6sSJE5gzZw5ee+01TYIjIo1xibzrVqxYgZdeeglPPfUU7r33XgwcOBB2ux3BwcH497//je+++w67du3CP//5T6SmpnJqICLym0YltTFjxuDAgQPYtWsXNm7ciA0bNuDUqVP4z3/+g3bt2qF///54/PHHMW3aNK7STqRnEgw/VV0oGD58OC8MEDVnTGpEZCgS3NLBJwqIyFBYqf2cq4Ltw7UIwksisYtOEmkWaHtZsG/R6YOMjE8UEJGhuCA+PtP5OTVVH+/atWtYt24dysu9mQmPiMj3VCW1Fi1aYPbs2aipER2bEJFfSHDzrepCdPDgwSgsLPRBKETkcy6NNh1TfU7tqaeeQlpaGkpKSjBgwACEhYV5fL9Pnz6aBUdEpJbqpPbwww8DAJ555hn3PpPJ5H7o3eXSeRonkpkE96mpTmrFxcW+iIOImoIEVz9VJ7XY2FhfxEFEpAmvcvb69esxbNgw2O12nDp1CgCwfPlyfPTRR5oGR0Qak+BCgeqktnLlSqSlpWHcuHGoqKhwn0MLDw/H8uXLtY6PiLSkQPx2DqXJo1ZFdVJbsWIF3n77bbz88ssIDPzxeZSBAwfiH//4h6bBEZHGWKnVV1xcjP79+9fbb7FYUF1drUlQRETeUp3U4uLiGrz5Nj8/Hz179tQiJiLyFQkqNdVXP9PS0jB37lzU1NRAURTs378f77//PjIzM7FmzRpfxEhEWuF9avU9+eSTCAkJwSuvvIIrV67g0Ucfhd1uxx//+Ef3jbm65IR3JzgjBfutFGgr+j9ikEDbK4J9Bwu0rRDsu41AW9ElbL/zos3t1zMilbyaemjatGmYNm0arly5gqqqKrRv317ruIjIF1wARFe71PnwU/U5tdGjR6OiogIAEBoa6k5oDocDo0eP1jQ4ItIYZ+mo7+uvv25w/c+amhrs3LlTk6CIiLzV6OHnkSNH3F9/9913KCsrc792uVzIz89Hhw6iJySIyKckGH42Oqn169cPJpMJJpOpwWFmSEgIVqxYoWlwRKQxrlHwo+LiYiiKgvj4eOzfvx8RERHu75nNZrRv397jCQMiIn9odFKLjY3F1atXMX36dLRt25azdRA1R3UQH37qvFJTdaEgKCgIW7Zs8VUsRORrEjxRoPrq5wMPPICtW7f6IBQi8jkJkprqm2+7deuGV199Fbt3725wjYKbp/kmImpqqpPaO++8g/DwcBw8eBAHDx70+J7JZGJSI9IzCc6pcY0CIploMXTU+fBTaAkGRVGgKDqfBpOIpOJVUlu3bh3uuusuhISEICQkBH369MH69eu1jo2ItKbzZz+XLVuGoUOHIjQ0FOHh4V4dQ/XwMzs7G4sWLUJqaiqGDRsGANi1axdmz56NixcvYv78+V4FQkRNQIuE5MOkVltbiylTpmDIkCF45513vDqGSVE5foyLi8OSJUvw+OOPe+xfu3YtFi9erLtzbg6HAzabDZW7AWtL9e1/6CvWf1uBOc2Uq2J9m9oJNK4R67usyvu2FrGu0VrgANVOsb7DDqtv46gCbMOAyspKWK1WsQBu1ceNv4POgFVw3U9HHWD7HigpKfGI12KxwGIR/de7Li8vD/PmzXPPCKSG6o937tw5DB06tN7+oUOH4ty5c6oDIKImpOF9ajExMbDZbO4tMzOzST/Kragefnbt2hWbNm3Cb37zG4/9GzduRLdu3TQLjIh8QMPhZ0OVmh6oTmpLlizB1KlTsWPHDvc5td27d6OgoACbNm3SPEAi0ier1dqo4fKCBQuQlZV12/ccPXoUPXr00CQu1Ult0qRJ2LdvH958803341I9e/bE/v37G1w6j4h0xAXxxYhVVnvPPfccZsyYcdv3xMfHex/PT3i1RsGAAQPw7rvvahYEETURPyS1iIgIj6nKfM2rpOZyubBlyxYcPXoUANCrVy888MADaNHCq8MRUVPR+S0dp0+fxqVLl3D69Gm4XC73GsNdu3ZFy5aNu31BdRb65z//iQkTJqCsrAx33HEHACArKwsRERH45JNP0Lt3b7WHJCICAKSnp2Pt2rXu1zdOaX311VcYOXJko46h+paOJ598EnfeeSfOnDmDQ4cO4dChQygpKUGfPn3w61//Wu3hiKgp3ZjOW2TzYaWWl5fnfvzy5q2xCQ3wolIrLCzEgQMH0Lp1a/e+1q1bY9myZRg0aJDawxFRU9Jilg6dP+6tulLr3r07ysvL6+0/f/48unbtqklQRETeUl2pZWZm4plnnsHixYvxy1/+EgCwd+9evPrqq8jKyoLD4XC/11ePfBCRl7RYIk/nlZrqpHb//fcDAB566CGYTNd/OjceHx0/frz7tclkgsul84mXiGTDpFbfV1995Ys4iIg0oTqpjRgxwhdxEFFTkOBCgVd3y+7cuROrV6/Gv/71L3z44Yfo0KED1q9fj7i4OAwfPlzrGLWxE0Cw+mZt79M8kkYziV46F3m+2CzWddQP/usbAtM9hYmeMfFmICM4zZMqEgw/VV/9/Mtf/oKkpCSEhITg0KFDcDqvT0BVWVmJ3/3ud5oHSESkhuqktnTpUqxatQpvv/02goJ+/C9x2LBhOHTokKbBEZHGuO5nfcePH8c999xTb7/NZvNqlkoiakIKdD98FKW6UouKikJRUVG9/bt27VI9fciOHTswfvx42O12mEymeiu/z5gxAyaTyWMbO3as2pCJ6P9IUKipT2qzZs3Cs88+i3379sFkMqG0tBQbNmzA888/jzlz5qg6VnV1Nfr27YucnJxbvmfs2LE4d+6ce3v//ffVhkxEElE9/FywYAHq6uowZswYXLlyBffccw8sFguef/55PP3006qOlZycjOTk5Nu+x2KxICoqSm2YRNQALSotvVdqqpOayWTCyy+/jBdeeAFFRUWoqqpCr1690LJlS/znP/9BSEiIpgF+/fXXaN++PVq3bo3Ro0dj6dKlaNu27S3f73Q63VdkAXg8tkUkOy2W7fThJB2a8HqxLLPZjF69emHw4MEICgpCdnY24uLitIwNY8eOxbp161BQUICsrCxs374dycnJt338KjMz02OFm5iYGE1jIiJ9a3Sl5nQ6sXjxYnzxxRcwm8148cUXMXHiROTm5uLll19GYGCg5gsZP/zww+6v77rrLvTp0wddunTB119/jTFjxjTYZuHChUhLS3O/djgcTGxE/4fDz5ukp6dj9erVSExMxDfffIMpU6YgJSUFe/fuRXZ2NqZMmYLAwEBfxor4+Hi0a9cORUVFt0xqWi6oSmQ0Mgw/G53UPvzwQ6xbtw4TJkzAt99+iz59+uDatWs4fPiwe7YOXztz5gx++OEHREdHN0l/RNT8NDqpnTlzBgMGDAAA9O7dGxaLBfPnzxdKaFVVVR73vBUXF6OwsBBt2rRBmzZtsGTJEkyaNAlRUVE4efIkXnzxRXTt2hVJSUle90kkMw4/b+JyuWA2//ikcYsWLRq9usutHDhwAKNGjXK/vnEubPr06Vi5ciWOHDmCtWvXoqKiAna7Hffddx9++9vfcnhJ5KUbSxSIHkPPGp3UFEXBjBkz3AmlpqYGs2fPRlhYmMf7Nm/e3OjOR44c6Z5gsiGfffZZo49FRASoSGrTp0/3eP3YY49pHgwR+RYvFNwkNzfXl3H4XPUCwJtrs2GXBTu+JNBWdJ6tCoG2op87QaBtpWDftQJtBedyq+7oRRuxLlXhOTUiMhQZkprXTxQQEekRKzUiifCcGhEZCoefRETNDCs1Iolw+ElEhiLDEwUcfhKRobBSI5KIDBcKmNSIJCLDOTUOP4nIUFipEUmEw08iMhQmNSIyFBnOqUmT1MLmAGHeTJi7QLBj365Fc3si/6WKxv2xQFuRqYMAsb86wTIkbJ4XXToBrBTrl34kTVIjIg4/ichgFIgPH289Ab8+8JYOIjIUVmpEEuHwk4gMRYakxuEnERkKKzUiifA+NSIyFA4/iYiaGVZqRBKRoVJjUiOSCM+pEZGhcI0CIqJmhpUakUQ4/DQSLf41vVEj0FZ0Ch4RYYLtqzWJwjtmgbain9ub37Em/L2U4UIBh59EZCjyVGpEJEWlxqRGJBEZzqlx+ElEhsJKjUgiHH4SkaHIkNQ4/CQiQ2GlRiQRGRZeYVIjkgiHn0RkKHUabb7w/fffY+bMmYiLi0NISAi6dOmCjIwM1Naqe7SGlRoR6cKxY8dQV1eH1atXo2vXrvj2228xa9YsVFdX44033mj0cZjUiCSi5fDT4XB47LdYLLBYLF4fd+zYsRg7dqz7dXx8PI4fP46VK1eqSmocfhJJxKXRBgAxMTGw2WzuLTMzU/N4Kysr0aZNG1VtWKkRkVdKSkpgtVrdr0WqtIYUFRVhxYoVqqo0gJUakVS0vFBgtVo9tlsltQULFsBkMt12O3bsmEebs2fPYuzYsZgyZQpmzZql6jPKU6kFwLsUHi/Yb4lA2zsE+74i0NYm2HcHgbYXBPsWaR8r2PdnXrS5KtinCv64peO5557DjBkzbvue+Pgf/9BKS0sxatQoDB06FH/6059UxydPUiMiv4iIiEBERESj3nv27FmMGjUKAwYMQG5uLgIC1FciTGpEEtHzwitnz57FyJEjERsbizfeeAMXLvxYckdFRTX6OExqRBLR83xqX3zxBYqKilBUVISOHTt6fE9RGv9wFi8UEJEuzJgxA4qiNLipwUqNSCIyPPvJpEYkET0PP7XCpEYkERkqNZ5TIyJDYaVGJBEZKjUmNSKJyHBOjcNPIjIUVmpEEtHzEwVaYVIjkogM59Q4/CQiQ5GnUgsG4M0cdtsE+60RaOvNNDY3myzQdrNg3yLTHsUI9i1C3Rof9XXzoo1JsE8VZLhQIE9SIyIOP4mImhtWakQSkWH46ddKLTMzE4MGDUKrVq3Qvn17TJw4EcePH/d4T01NDebOnYu2bduiZcuWmDRpEsrLy/0UMVHzpuVqUnrl16S2fft2zJ07F3v37sUXX3yBq1ev4r777kN1dbX7PfPnz8cnn3yCDz/8ENu3b0dpaSl+9atf+TFqouZLhqTm1+Fnfn6+x+u8vDy0b98eBw8exD333IPKykq88847eO+99zB69GgAQG5uLnr27Im9e/fil7/8pT/CJiId09WFgsrKSgBwL1568OBBXL16FYmJie739OjRA506dcKePXsaPIbT6YTD4fDYiOg6BeLL46mbh7bp6Sap1dXVYd68eRg2bBh69+4NACgrK4PZbEZ4eLjHeyMjI1FWVtbgcTIzMz1WjY6J8edNT0T6IsPwUzdJbe7cufj222/xwQcfCB1n4cKFqKysdG8lJSILbxJRc6OLWzpSU1Px17/+FTt27PBYRSYqKgq1tbWoqKjwqNbKy8tvuWSWxWK55UrRRLLjzbc+pigKUlNTsWXLFmzbtg1xcXEe3x8wYACCgoJQUFDg3nf8+HGcPn0aQ4YMaepwiZo90fNpWtzn5mt+rdTmzp2L9957Dx999BFatWrlPk9ms9kQEhICm82GmTNnIi0tDW3atIHVasXTTz+NIUOG8MonETXIr0lt5cqVAICRI0d67M/NzcWMGTMAAG+++SYCAgIwadIkOJ1OJCUl4X/+53+aOFIiY5Bh+OnXpNaYRUqDg4ORk5ODnJycJoiIyNj4mBQRUTOji6ufTaIK3s2VFSzYbxuBtm0F+xa5myVesO8igbYic9ABQIVAW9F/b53j8JOIDIVrFBCRofCcGhFRM8NKjUgiLohXMjynRkS6IUNS4/CTiAyFlRqRRGS4UMCkRiQRDj+JiJoZVmpEEuHwk4gMRYYnCjj8JCJDYaVGJBEXAJMGx9AzJjUiifCcmoHkvQ2EeNFunmC/gQJtHRcEO98i0HaNYN95Am17iq4s+Y73TU8+Kdb1o160acLSR4ZKjefUiMhQpKnUiEiOSo1JjUgiMpxT4/CTiAyFlRqRRDj8JCJDUSA+fBS9Nu1rHH4SkaGwUiOSiBZDRw4/iUg3ZEhqHH4SkaGwUiOSSB3Er37q/T41JjUiicgw/GRSI5KIDEmN59SIyFBYqRFJhOfUDGTGbsDaUn27WeFi/SqxAo0XiPWNjwTaHhTs+7L3TQtNYn92QQJtTwn1DIxT7lXfyHENsH0l2HPjaJGQ9J7UOPwkIkORplIjIjkqNSY1Iom4IP5Aut6TGoefRKQbEyZMQKdOnRAcHIzo6Gj813/9F0pLS1Udg0mNSCIujTZfGTVqFDZt2oTjx4/jL3/5C06ePInJkyerOgaHn0QS0fs5tfnz57u/jo2NxYIFCzBx4kRcvXoVQUGNu67NpEZEXnE4HB6vLRYLLBaLZse/dOkSNmzYgKFDhzY6oQEcfhJJRcvhZ0xMDGw2m3vLzMzUJMaXXnoJYWFhaNu2LU6fPo2PPlJ3wyWTGpFE6iCe0G4MP0tKSlBZWeneFi5c2GCfCxYsgMlkuu127Ngx9/tfeOEF/P3vf8fnn3+OwMBAPP7441CUxl+z5fCTSCJaPCZ1I71YrVZYrdafff9zzz2HGTNm3PY98fHx7q/btWuHdu3aoXv37ujZsydiYmKwd+9eDBkypFHxMakRkU9FREQgIiLCq7Z1ddfrQqfT2eg2TGpEEtFiiTxfrSa1b98+/O1vf8Pw4cPRunVrnDx5EosWLUKXLl0aXaUBPKdGJJU6jTZfCA0NxebNmzFmzBjccccdmDlzJvr06YPt27eruqpq+ErtxglGR7WXBwgU7F+gralWrG+h3z6BWTYAAFV+aQpAbJaOK4J9OxzXvG6j5mS4t7TowVdR3nXXXdi2bZvwcQyf1C5fvv7XGXOfnwPxxno/9t3bj303ZwJTCF2+fBk2m03DYH5kNpsRFRWFsrIyTY4XFRUFs9msybG0ZlKa4r8HP6qrq0NpaSlatWoFUwPzdDkcDsTExKCkpKRRV3KIPzNv3O5npigKLl++DLvdjoAA350RqqmpQW2taPl/ndlsRnBwsCbH0prhK7WAgAB07NjxZ9/X2MvT9CP+zNS71c/MVxXazYKDg3WbiLTECwVEZChMakRkKNInNYvFgoyMDE0fxDU6/szU48+s6Rj+QgERyUX6So2IjIVJjYgMhUmNiAyFSY2IDEXqpJaTk4POnTsjODgYCQkJ2L9/v79D0q3FixfXm9ivR48e/g5LV3bs2IHx48fDbrfDZDJh69atHt9XFAXp6emIjo5GSEgIEhMTceLECf8Ea2DSJrWNGzciLS0NGRkZOHToEPr27YukpCScP3/e36Hp1p133olz5865t127dvk7JF2prq5G3759kZOT0+D3X3/9dbz11ltYtWoV9u3bh7CwMCQlJaGmpqaJIzU4RVKDBw9W5s6d637tcrkUu92uZGZm+jEq/crIyFD69u3r7zCaDQDKli1b3K/r6uqUqKgo5fe//717X0VFhWKxWJT333/fDxEal5SVWm1tLQ4ePIjExET3voCAACQmJmLPnj1+jEzfTpw4Abvdjvj4eEybNg2nT5/2d0jNRnFxMcrKyjx+52w2GxISEvg7pzEpk9rFixfhcrkQGRnpsT8yMlKzqVmMJiEhAXl5ecjPz8fKlStRXFyMu+++2z21E93ejd8r/s75nuFn6SBtJCcnu7/u06cPEhISEBsbi02bNmHmzJl+jIzIk5SVWrt27RAYGIjy8nKP/eXl5YiKivJTVM1LeHg4unfvjqKiIn+H0izc+L3i75zvSZnUzGYzBgwYgIKCAve+uro6FBQUqFrgQWZVVVU4efIkoqOj/R1KsxAXF4eoqCiP3zmHw4F9+/bxd05j0g4/09LSMH36dAwcOBCDBw/G8uXLUV1djZSUFH+HpkvPP/88xo8fj9jYWJSWliIjIwOBgYF45JFH/B2ablRVVXlUrsXFxSgsLESbNm3QqVMnzJs3D0uXLkW3bt0QFxeHRYsWwW63Y+LEif4L2oj8ffnVn1asWKF06tRJMZvNyuDBg5W9e/f6OyTdmjp1qhIdHa2YzWalQ4cOytSpU5WioiJ/h6UrX331lYLr65J4bNOnT1cU5fptHYsWLVIiIyMVi8WijBkzRjl+/Lh/gzYgTj1ERIYi5Tk1IjIuJjUiMhQmNSIyFCY1IjIUJjUiMhQmNSIyFCY1IjIUJjUiMhQmNfpZ33//PUwmEwoLC/0dCtHPYlKTxE/XF/jptnjxYn+HSKQJaR9ol825c+fcX2/cuBHp6ek4fvy4e1/Lli39ERaR5lipSSIqKsq92Ww2mEwm9+v27dsjOzsbHTt2hMViQb9+/ZCfn3/LY7lcLjzxxBPo0aOHe0rvjz76CL/4xS8QHByM+Ph4LFmyBNeuXXO3MZlMWLNmDR588EGEhoaiW7du+Pjjj33+uUk+TGqEP/7xj/jDH/6AN954A0eOHEFSUhImTJjQ4PJtTqcTU6ZMQWFhIXbu3IlOnTph586dePzxx/Hss8/iu+++w+rVq5GXl4dly5Z5tF2yZAkeeughHDlyBOPGjcO0adNw6dKlpvqYJAt/TxNCTS83N1ex2Wzu13a7XVm2bJnHewYNGqQ89dRTiqIoSnFxsQJA2blzpzJmzBhl+PDhSkVFhfu9Y8aMUX73u995tF+/fr0SHR3tfg1AeeWVV9yvq6qqFADKp59+quVHI1J4Tk1yDocDpaWlGDZsmMf+YcOG4fDhwx77HnnkEXTs2BHbtm1DSEiIe//hw4exe/duj8rM5XKhpqYGV65cQWhoKIDraxvcEBYWBqvVynVWSXNMatRo48aNw7vvvos9e/Zg9OjR7v1VVVVYsmQJfvWrX9VrExwc7P46KCjI43smkwl1dXW+C5ikxKQmOavVCrvdjt27d2PEiBHu/bt378bgwYM93jtnzhz07t0bEyZMwP/+7/+63/+LX/wCx48fR9euXZs0dqKGMKkRXnjhBWRkZKBLly7o168fcnNzUVhYiA0bNtR779NPPw2Xy4X7778fn376KYYPH4709HTcf//96NSpEyZPnoyAgAAcPnwY3377LZYuXeqHT0QyY1IjPPPMM6isrMRzzz2H8+fPo1evXvj444/RrVu3Bt8/b9481NXVYdy4ccjPz0dSUhL++te/4tVXX0VWVhaCgoLQo0cPPPnkk038SYgArlFARIbC+9SIyFCY1IjIUJjUiMhQmNSIyFCY1IjIUJjUiMhQmNSIyFCY1IjIUJjUiMhQmNSIyFCY1IjIUP4/5hc5HfLnM1gAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_2d_tensor_as_heatmap(reporter_outputs(reporters, sentence))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elk.extraction.prompt_dataset import PromptConfig\n",
    "from elk.promptsource.templates import DatasetTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Tried instantiating `DatasetTemplates` for asdfdsfdf, but no prompts found. Please ignore this warning if you are creating new prompts for this dataset.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<elk.promptsource.templates.DatasetTemplates at 0x7f947180d9f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DatasetTemplates(\"asdfdsfdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptConfig(dataset='asdffdfd', balance=False, label_column=None, max_examples=[], num_shots=0, seed=42, num_variants=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PromptConfig(\"asdffdfd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_config = PromptConfig(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptConfig(dataset='imdb', balance=False, label_column=None, max_examples=[], num_shots=0, seed=42, num_variants=1)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_config.num_variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/admin/home-rudolf/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1228eabf22a6494d805c885d24b75e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /admin/home-rudolf/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-9c48ce5d173413c7.arrow\n"
     ]
    }
   ],
   "source": [
    "prompts = PromptDataset(prompt_config, \"boolq\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prompt(question='This movie is a great. The plot is very true to the book which is a classic written by Mark Twain. The movie starts of with a scene where Hank sings a song with a bunch of kids called \"when you stub your toe on the moon\" It reminds me of Sinatra\\'s song High Hopes, it is fun and inspirational. The Music is great throughout and my favorite song is sung by the King, Hank (bing Crosby) and Sir \"Saggy\" Sagamore. OVerall a great family movie or even a great Date movie. This is a movie you can watch over and over again. The princess played by Rhonda Fleming is gorgeous. I love this movie!! If you liked Danny Kaye in the Court Jester then you will definitely like this movie. Did the reviewer find this movie good or bad?', answers=['bad', 'good'], label=1, template_name='2351d12a-e630-4d19-8b41-e199266e38f7')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = prompts[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prompt(question='This movie is a great. The plot is very true to the book which is a classic written by Mark Twain. The movie starts of with a scene where Hank sings a song with a bunch of kids called \"when you stub your toe on the moon\" It reminds me of Sinatra\\'s song High Hopes, it is fun and inspirational. The Music is great throughout and my favorite song is sung by the King, Hank (bing Crosby) and Sir \"Saggy\" Sagamore. OVerall a great family movie or even a great Date movie. This is a movie you can watch over and over again. The princess played by Rhonda Fleming is gorgeous. I love this movie!! If you liked Danny Kaye in the Court Jester then you will definitely like this movie. How does the viewer feel about the movie?', answers=['negative', 'positive'], label=1, template_name='866474a5-1498-46b7-bfee-ac0c5160707f')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ccs_pair(prompt):\n",
    "    return (\n",
    "        f\"{prompt.question} {prompt.answers[0]}\",\n",
    "        f\"{prompt.question} {prompt.answers[1]}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('This movie is a great. The plot is very true to the book which is a classic written by Mark Twain. The movie starts of with a scene where Hank sings a song with a bunch of kids called \"when you stub your toe on the moon\" It reminds me of Sinatra\\'s song High Hopes, it is fun and inspirational. The Music is great throughout and my favorite song is sung by the King, Hank (bing Crosby) and Sir \"Saggy\" Sagamore. OVerall a great family movie or even a great Date movie. This is a movie you can watch over and over again. The princess played by Rhonda Fleming is gorgeous. I love this movie!! If you liked Danny Kaye in the Court Jester then you will definitely like this movie. \\nIs this review positive or negative? negative',\n",
       " 'This movie is a great. The plot is very true to the book which is a classic written by Mark Twain. The movie starts of with a scene where Hank sings a song with a bunch of kids called \"when you stub your toe on the moon\" It reminds me of Sinatra\\'s song High Hopes, it is fun and inspirational. The Music is great throughout and my favorite song is sung by the King, Hank (bing Crosby) and Sir \"Saggy\" Sagamore. OVerall a great family movie or even a great Date movie. This is a movie you can watch over and over again. The princess played by Rhonda Fleming is gorgeous. I love this movie!! If you liked Danny Kaye in the Court Jester then you will definitely like this movie. \\nIs this review positive or negative? positive')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ccs_pair(prompts[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative ||| positive',\n",
       " 'bad ||| good',\n",
       " 'negative ||| positive',\n",
       " 'negative ||| positive',\n",
       " 'negative ||| positive',\n",
       " 'negative ||| positive',\n",
       " 'negative ||| positive',\n",
       " 'negative ||| positive',\n",
       " 'No ||| Yes',\n",
       " 'negative ||| positive',\n",
       " '0 ||| 1',\n",
       " \"They didn't like it! ||| They loved it\",\n",
       " '0 ||| 1']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    x.answer_choices for x in\n",
    "    list(prompts.prompter.templates.values())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The following movie review expresses what sentiment? In the process of trying to establish the audiences' empathy with Jake Roedel (Tobey Maguire) the filmmakers slander the North and the Jayhawkers. Missouri never withdrew from the Union and the Union Army was not an invading force. The Southerners fought for State's Rights: the right to own slaves, elect crooked legislatures and judges, and employ a political spoils system. There's nothing noble in that. The Missourians could have easily traveled east and joined the Confederate Army.<br /><br />It seems to me that the story has nothing to do with ambiguity. When Jake leaves the Bushwhackers, it's not because he saw error in his way, he certainly doesn't give himself over to the virtue of the cause of abolition.\",\n",
       " 'positive']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(prompts.prompter.templates.values())[0].apply(\n",
    "    prompts.active_split[3]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With boolq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "# dataset = datasets.load_dataset(\"boolq\", split=\"train\")\n",
    "# dataset[999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset dbpedia_14 (/admin/home-rudolf/.cache/huggingface/datasets/dbpedia_14/dbpedia_14/2.0.0/01dab9e10d969eadcdbc918be5a09c9190a24caeae33b10eee8f367a1e3f1f0c)\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(\"dbpedia_14\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_config = PromptConfig(\"dbpedia_14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 8,\n",
       " 'title': 'Kanni Banmauk',\n",
       " 'content': ' Kanni is a village in Banmauk Township Katha District in the Sagaing Region of northern-central Burma.'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts.active_split[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Consider the following example: '''  Kanni is a village in Banmauk Township Katha District in the Sagaing Region of northern-central Burma. '''\\nChoice 1: Village. Choice 2: Plant.Between choice 1 and choice 2, what is the topic of this example?\",\n",
       " 'Village']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(prompts.prompter.templates.values())[1].apply(\n",
    "    prompts.active_split[3]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset dbpedia_14 (/admin/home-rudolf/.cache/huggingface/datasets/dbpedia_14/dbpedia_14/2.0.0/01dab9e10d969eadcdbc918be5a09c9190a24caeae33b10eee8f367a1e3f1f0c)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb5706e8a6e4b5bb7876adc4e8765bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /admin/home-rudolf/.cache/huggingface/datasets/dbpedia_14/dbpedia_14/2.0.0/01dab9e10d969eadcdbc918be5a09c9190a24caeae33b10eee8f367a1e3f1f0c/cache-8d3084efc09afa17.arrow\n"
     ]
    }
   ],
   "source": [
    "prompts = PromptDataset(prompt_config, \"dbpedia_14\", split=\"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Company',\n",
       " 'EducationalInstitution',\n",
       " 'Artist',\n",
       " 'Athlete',\n",
       " 'OfficeHolder',\n",
       " 'MeanOfTransportation',\n",
       " 'Building',\n",
       " 'NaturalPlace',\n",
       " 'Village',\n",
       " 'Animal',\n",
       " 'Plant',\n",
       " 'Album',\n",
       " 'Film',\n",
       " 'WrittenWork']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts.active_split.features[\"label\"].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The length of questions is 14, needs to be 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m prompts[\u001b[39m0\u001b[39;49m]\n",
      "File \u001b[0;32m/fsx/home-rudolf/elk/elk/elk/extraction/prompt_dataset.py:203\u001b[0m, in \u001b[0;36mPromptDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    200\u001b[0m     answers\u001b[39m.\u001b[39mappend(a)\n\u001b[1;32m    201\u001b[0m     questions\u001b[39m.\u001b[39madd(q)\n\u001b[0;32m--> 203\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(questions) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe length of questions is \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(questions)\u001b[39m}\u001b[39;00m\u001b[39m, needs to be 1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    204\u001b[0m question \u001b[39m=\u001b[39m questions\u001b[39m.\u001b[39mpop()\n\u001b[1;32m    206\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_shots \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    207\u001b[0m     \u001b[39m# Use stratified sampling to get `num_shots` examples from train set.\u001b[39;00m\n\u001b[1;32m    208\u001b[0m     \u001b[39m# If `num_shots` is not divisible by the number of classes, stochastic\u001b[39;00m\n\u001b[1;32m    209\u001b[0m     \u001b[39m# rounding is used to determine the number of examples per class.\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: The length of questions is 14, needs to be 1"
     ]
    }
   ],
   "source": [
    "prompts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[106], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(prompts[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mquestion)\n\u001b[1;32m      2\u001b[0m [\n\u001b[1;32m      3\u001b[0m     x\u001b[39m.\u001b[39manswer_choices \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[39mlist\u001b[39m(prompts\u001b[39m.\u001b[39mprompter\u001b[39m.\u001b[39mtemplates\u001b[39m.\u001b[39mvalues())\n\u001b[1;32m      5\u001b[0m ]\n",
      "File \u001b[0;32m/fsx/home-rudolf/elk/elk/elk/extraction/prompt_dataset.py:203\u001b[0m, in \u001b[0;36mPromptDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    200\u001b[0m     answers\u001b[39m.\u001b[39mappend(a)\n\u001b[1;32m    201\u001b[0m     questions\u001b[39m.\u001b[39madd(q)\n\u001b[0;32m--> 203\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(questions) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    204\u001b[0m question \u001b[39m=\u001b[39m questions\u001b[39m.\u001b[39mpop()\n\u001b[1;32m    206\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_shots \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    207\u001b[0m     \u001b[39m# Use stratified sampling to get `num_shots` examples from train set.\u001b[39;00m\n\u001b[1;32m    208\u001b[0m     \u001b[39m# If `num_shots` is not divisible by the number of classes, stochastic\u001b[39;00m\n\u001b[1;32m    209\u001b[0m     \u001b[39m# rounding is used to determine the number of examples per class.\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(prompts[0][0].question)\n",
    "[\n",
    "    x.answer_choices for x in\n",
    "    list(prompts.prompter.templates.values())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Failed attempts at using existing code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_config = ExtractionConfig(\n",
    "    prompt_config,\n",
    "    \"microsoft/deberta-v3-large\",\n",
    "    layers = [1],\n",
    "    token_loc = \"last\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "exgen = extract_hiddens(extract_config, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/admin/home-rudolf/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36dc5b909d254dcc84cfe1f6d5fb4230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /admin/home-rudolf/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-9c48ce5d173413c7.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 prompts per example: ['Movie Expressed Sentiment', 'Movie Expressed Sentiment 2', 'Negation template for positive and negative', 'Reviewer Enjoyment', 'Reviewer Enjoyment Yes No', 'Reviewer Expressed Sentiment', 'Reviewer Opinion bad good choices', 'Reviewer Sentiment Feeling', 'Sentiment with choices ', 'Text Expressed Sentiment', 'Writer Expressed Sentiment', 'burns_1', 'burns_2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/fsx/home-rudolf/miniconda3/envs/elk2/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:446: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\"LayerNormKernelImpl\" not implemented for 'Half'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mnext\u001b[39;49m(exgen)\n",
      "File \u001b[0;32m/fsx/home-rudolf/elk/elk/elk/extraction/extraction.py:181\u001b[0m, in \u001b[0;36mextract_hiddens\u001b[0;34m(cfg, device, rank, split, world_size)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39mfor\u001b[39;00m i, variant_inputs \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(inputs):\n\u001b[1;32m    179\u001b[0m     \u001b[39m# Iterate over answers\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     \u001b[39mfor\u001b[39;00m j, inpt \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(variant_inputs):\n\u001b[0;32m--> 181\u001b[0m         outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minpt, output_hidden_states\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    183\u001b[0m         hiddens \u001b[39m=\u001b[39m (\n\u001b[1;32m    184\u001b[0m             outputs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdecoder_hidden_states\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m outputs[\u001b[39m\"\u001b[39m\u001b[39mhidden_states\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    185\u001b[0m         )\n\u001b[1;32m    186\u001b[0m         \u001b[39m# First element of list is the input embeddings\u001b[39;00m\n",
      "File \u001b[0;32m/fsx/home-rudolf/miniconda3/envs/elk2/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/fsx/home-rudolf/miniconda3/envs/elk2/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:1076\u001b[0m, in \u001b[0;36mDebertaV2Model.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[39mif\u001b[39;00m token_type_ids \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1074\u001b[0m     token_type_ids \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(input_shape, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong, device\u001b[39m=\u001b[39mdevice)\n\u001b[0;32m-> 1076\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membeddings(\n\u001b[1;32m   1077\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m   1078\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1079\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1080\u001b[0m     mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1081\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1082\u001b[0m )\n\u001b[1;32m   1084\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(\n\u001b[1;32m   1085\u001b[0m     embedding_output,\n\u001b[1;32m   1086\u001b[0m     attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1089\u001b[0m     return_dict\u001b[39m=\u001b[39mreturn_dict,\n\u001b[1;32m   1090\u001b[0m )\n\u001b[1;32m   1091\u001b[0m encoded_layers \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m/fsx/home-rudolf/miniconda3/envs/elk2/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/fsx/home-rudolf/miniconda3/envs/elk2/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:901\u001b[0m, in \u001b[0;36mDebertaV2Embeddings.forward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, mask, inputs_embeds)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_size \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mhidden_size:\n\u001b[1;32m    899\u001b[0m     embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_proj(embeddings)\n\u001b[0;32m--> 901\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mLayerNorm(embeddings)\n\u001b[1;32m    903\u001b[0m \u001b[39mif\u001b[39;00m mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    904\u001b[0m     \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39mdim() \u001b[39m!=\u001b[39m embeddings\u001b[39m.\u001b[39mdim():\n",
      "File \u001b[0;32m/fsx/home-rudolf/miniconda3/envs/elk2/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/fsx/home-rudolf/miniconda3/envs/elk2/lib/python3.10/site-packages/torch/nn/modules/normalization.py:190\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 190\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlayer_norm(\n\u001b[1;32m    191\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnormalized_shape, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps)\n",
      "File \u001b[0;32m/fsx/home-rudolf/miniconda3/envs/elk2/lib/python3.10/site-packages/torch/nn/functional.py:2515\u001b[0m, in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2511\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_variadic(\u001b[39minput\u001b[39m, weight, bias):\n\u001b[1;32m   2512\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2513\u001b[0m         layer_norm, (\u001b[39minput\u001b[39m, weight, bias), \u001b[39minput\u001b[39m, normalized_shape, weight\u001b[39m=\u001b[39mweight, bias\u001b[39m=\u001b[39mbias, eps\u001b[39m=\u001b[39meps\n\u001b[1;32m   2514\u001b[0m     )\n\u001b[0;32m-> 2515\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mlayer_norm(\u001b[39minput\u001b[39;49m, normalized_shape, weight, bias, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \"LayerNormKernelImpl\" not implemented for 'Half'"
     ]
    }
   ],
   "source": [
    "next(exgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 of 8 GPUs: [0]\n",
      "Downloading and preparing dataset generator/default to /admin/home-rudolf/.cache/huggingface/datasets/generator/default-8f6699946cfc77af/0.0.0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ec4db0c15644fc9994cd7e23cfbf25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/admin/home-rudolf/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9263e0e4c1da4dc1beb3eebee82879be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /admin/home-rudolf/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-9c48ce5d173413c7.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 prompts per example: ['Movie Expressed Sentiment', 'Movie Expressed Sentiment 2', 'Negation template for positive and negative', 'Reviewer Enjoyment', 'Reviewer Enjoyment Yes No', 'Reviewer Expressed Sentiment', 'Reviewer Opinion bad good choices', 'Reviewer Sentiment Feeling', 'Sentiment with choices ', 'Text Expressed Sentiment', 'Writer Expressed Sentiment', 'burns_1', 'burns_2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/fsx/home-rudolf/miniconda3/envs/elk2/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:446: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m exgen \u001b[39m=\u001b[39m extract(extract_config, max_gpus\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m/fsx/home-rudolf/elk/elk/elk/extraction/extraction.py:301\u001b[0m, in \u001b[0;36mextract\u001b[0;34m(cfg, max_gpus)\u001b[0m\n\u001b[1;32m    299\u001b[0m ds \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[1;32m    300\u001b[0m \u001b[39mfor\u001b[39;00m split, builder \u001b[39min\u001b[39;00m builders\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 301\u001b[0m     builder\u001b[39m.\u001b[39;49mdownload_and_prepare(num_proc\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(devices))\n\u001b[1;32m    302\u001b[0m     ds[split] \u001b[39m=\u001b[39m builder\u001b[39m.\u001b[39mas_dataset(split\u001b[39m=\u001b[39msplit)\n\u001b[1;32m    303\u001b[0m \u001b[39mreturn\u001b[39;00m DatasetDict(ds)\n",
      "File \u001b[0;32m/fsx/home-rudolf/miniconda3/envs/elk2/lib/python3.10/site-packages/datasets/builder.py:872\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[0;34m(self, output_dir, download_config, download_mode, verification_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m    870\u001b[0m     \u001b[39mif\u001b[39;00m num_proc \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         prepare_split_kwargs[\u001b[39m\"\u001b[39m\u001b[39mnum_proc\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m num_proc\n\u001b[0;32m--> 872\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_download_and_prepare(\n\u001b[1;32m    873\u001b[0m         dl_manager\u001b[39m=\u001b[39;49mdl_manager,\n\u001b[1;32m    874\u001b[0m         verification_mode\u001b[39m=\u001b[39;49mverification_mode,\n\u001b[1;32m    875\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mprepare_split_kwargs,\n\u001b[1;32m    876\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdownload_and_prepare_kwargs,\n\u001b[1;32m    877\u001b[0m     )\n\u001b[1;32m    878\u001b[0m \u001b[39m# Sync info\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdataset_size \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(split\u001b[39m.\u001b[39mnum_bytes \u001b[39mfor\u001b[39;00m split \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39msplits\u001b[39m.\u001b[39mvalues())\n",
      "File \u001b[0;32m/fsx/home-rudolf/miniconda3/envs/elk2/lib/python3.10/site-packages/datasets/builder.py:1649\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_splits_kwargs)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_download_and_prepare\u001b[39m(\u001b[39mself\u001b[39m, dl_manager, verification_mode, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mprepare_splits_kwargs):\n\u001b[0;32m-> 1649\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_download_and_prepare(\n\u001b[1;32m   1650\u001b[0m         dl_manager,\n\u001b[1;32m   1651\u001b[0m         verification_mode,\n\u001b[1;32m   1652\u001b[0m         check_duplicate_keys\u001b[39m=\u001b[39;49mverification_mode \u001b[39m==\u001b[39;49m VerificationMode\u001b[39m.\u001b[39;49mBASIC_CHECKS\n\u001b[1;32m   1653\u001b[0m         \u001b[39mor\u001b[39;49;00m verification_mode \u001b[39m==\u001b[39;49m VerificationMode\u001b[39m.\u001b[39;49mALL_CHECKS,\n\u001b[1;32m   1654\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mprepare_splits_kwargs,\n\u001b[1;32m   1655\u001b[0m     )\n",
      "File \u001b[0;32m/fsx/home-rudolf/miniconda3/envs/elk2/lib/python3.10/site-packages/datasets/builder.py:967\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m split_dict\u001b[39m.\u001b[39madd(split_generator\u001b[39m.\u001b[39msplit_info)\n\u001b[1;32m    965\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    966\u001b[0m     \u001b[39m# Prepare split will record examples associated to the split\u001b[39;00m\n\u001b[0;32m--> 967\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_split(split_generator, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mprepare_split_kwargs)\n\u001b[1;32m    968\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    969\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[1;32m    970\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot find data file. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    971\u001b[0m         \u001b[39m+\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmanual_download_instructions \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    972\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mOriginal error:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    973\u001b[0m         \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)\n\u001b[1;32m    974\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[0;32m/fsx/home-rudolf/miniconda3/envs/elk2/lib/python3.10/site-packages/datasets/builder.py:1488\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._prepare_split\u001b[0;34m(self, split_generator, check_duplicate_keys, file_format, num_proc, max_shard_size)\u001b[0m\n\u001b[1;32m   1486\u001b[0m gen_kwargs \u001b[39m=\u001b[39m split_generator\u001b[39m.\u001b[39mgen_kwargs\n\u001b[1;32m   1487\u001b[0m job_id \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1488\u001b[0m \u001b[39mfor\u001b[39;00m job_id, done, content \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_split_single(\n\u001b[1;32m   1489\u001b[0m     gen_kwargs\u001b[39m=\u001b[39mgen_kwargs, job_id\u001b[39m=\u001b[39mjob_id, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_prepare_split_args\n\u001b[1;32m   1490\u001b[0m ):\n\u001b[1;32m   1491\u001b[0m     \u001b[39mif\u001b[39;00m done:\n\u001b[1;32m   1492\u001b[0m         result \u001b[39m=\u001b[39m content\n",
      "File \u001b[0;32m/fsx/home-rudolf/miniconda3/envs/elk2/lib/python3.10/site-packages/datasets/builder.py:1608\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._prepare_split_single\u001b[0;34m(self, gen_kwargs, fpath, file_format, max_shard_size, split_info, check_duplicate_keys, job_id)\u001b[0m\n\u001b[1;32m   1606\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1607\u001b[0m     _time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m-> 1608\u001b[0m     \u001b[39mfor\u001b[39;00m key, record \u001b[39min\u001b[39;00m generator:\n\u001b[1;32m   1609\u001b[0m         \u001b[39mif\u001b[39;00m max_shard_size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m writer\u001b[39m.\u001b[39m_num_bytes \u001b[39m>\u001b[39m max_shard_size:\n\u001b[1;32m   1610\u001b[0m             num_examples, num_bytes \u001b[39m=\u001b[39m writer\u001b[39m.\u001b[39mfinalize()\n",
      "File \u001b[0;32m/fsx/home-rudolf/elk/elk/elk/extraction/generator.py:56\u001b[0m, in \u001b[0;36m_GeneratorBuilder._generate_examples\u001b[0;34m(self, **gen_kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_generate_examples\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mgen_kwargs):\n\u001b[1;32m     55\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mgenerator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mgenerator must be specified\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 56\u001b[0m     \u001b[39mfor\u001b[39;00m idx, ex \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mgenerator(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mgen_kwargs)):\n\u001b[1;32m     57\u001b[0m         \u001b[39myield\u001b[39;00m idx, ex\n",
      "File \u001b[0;32m/fsx/home-rudolf/elk/elk/elk/extraction/extraction.py:214\u001b[0m, in \u001b[0;36m_extraction_worker\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_extraction_worker\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 214\u001b[0m     \u001b[39myield from\u001b[39;00m extract_hiddens(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{k: v[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m kwargs\u001b[39m.\u001b[39mitems()})\n",
      "File \u001b[0;32m/fsx/home-rudolf/elk/elk/elk/extraction/extraction.py:181\u001b[0m, in \u001b[0;36mextract_hiddens\u001b[0;34m(cfg, device, rank, split, world_size)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39mfor\u001b[39;00m i, variant_inputs \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(inputs):\n\u001b[1;32m    179\u001b[0m     \u001b[39m# Iterate over answers\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     \u001b[39mfor\u001b[39;00m j, inpt \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(variant_inputs):\n\u001b[0;32m--> 181\u001b[0m         outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minpt, output_hidden_states\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    183\u001b[0m         hiddens \u001b[39m=\u001b[39m (\n\u001b[1;32m    184\u001b[0m             outputs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdecoder_hidden_states\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m outputs[\u001b[39m\"\u001b[39m\u001b[39mhidden_states\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    185\u001b[0m         )\n\u001b[1;32m    186\u001b[0m         \u001b[39m# First element of list is the input embeddings\u001b[39;00m\n",
      "File \u001b[0;32m/fsx/home-rudolf/miniconda3/envs/elk2/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/fsx/home-rudolf/miniconda3/envs/elk2/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:1084\u001b[0m, in \u001b[0;36mDebertaV2Model.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     token_type_ids \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(input_shape, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong, device\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m   1076\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m   1077\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m   1078\u001b[0m     token_type_ids\u001b[39m=\u001b[39mtoken_type_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1081\u001b[0m     inputs_embeds\u001b[39m=\u001b[39minputs_embeds,\n\u001b[1;32m   1082\u001b[0m )\n\u001b[0;32m-> 1084\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1085\u001b[0m     embedding_output,\n\u001b[1;32m   1086\u001b[0m     attention_mask,\n\u001b[1;32m   1087\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1088\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1089\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1090\u001b[0m )\n\u001b[1;32m   1091\u001b[0m encoded_layers \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m1\u001b[39m]\n\u001b[1;32m   1093\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mz_steps \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m/fsx/home-rudolf/miniconda3/envs/elk2/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/fsx/home-rudolf/miniconda3/envs/elk2/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:522\u001b[0m, in \u001b[0;36mDebertaV2Encoder.forward\u001b[0;34m(self, hidden_states, attention_mask, output_hidden_states, output_attentions, query_states, relative_pos, return_dict)\u001b[0m\n\u001b[1;32m    513\u001b[0m     output_states \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    514\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    515\u001b[0m         next_kv,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         rel_embeddings,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[1;32m    521\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 522\u001b[0m     output_states \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    523\u001b[0m         next_kv,\n\u001b[1;32m    524\u001b[0m         attention_mask,\n\u001b[1;32m    525\u001b[0m         query_states\u001b[39m=\u001b[39;49mquery_states,\n\u001b[1;32m    526\u001b[0m         relative_pos\u001b[39m=\u001b[39;49mrelative_pos,\n\u001b[1;32m    527\u001b[0m         rel_embeddings\u001b[39m=\u001b[39;49mrel_embeddings,\n\u001b[1;32m    528\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    529\u001b[0m     )\n\u001b[1;32m    531\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n\u001b[1;32m    532\u001b[0m     output_states, att_m \u001b[39m=\u001b[39m output_states\n",
      "File \u001b[0;32m/fsx/home-rudolf/miniconda3/envs/elk2/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/fsx/home-rudolf/miniconda3/envs/elk2/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:362\u001b[0m, in \u001b[0;36mDebertaV2Layer.forward\u001b[0;34m(self, hidden_states, attention_mask, query_states, relative_pos, rel_embeddings, output_attentions)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    354\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    355\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    360\u001b[0m     output_attentions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    361\u001b[0m ):\n\u001b[0;32m--> 362\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    363\u001b[0m         hidden_states,\n\u001b[1;32m    364\u001b[0m         attention_mask,\n\u001b[1;32m    365\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    366\u001b[0m         query_states\u001b[39m=\u001b[39;49mquery_states,\n\u001b[1;32m    367\u001b[0m         relative_pos\u001b[39m=\u001b[39;49mrelative_pos,\n\u001b[1;32m    368\u001b[0m         rel_embeddings\u001b[39m=\u001b[39;49mrel_embeddings,\n\u001b[1;32m    369\u001b[0m     )\n\u001b[1;32m    370\u001b[0m     \u001b[39mif\u001b[39;00m output_attentions:\n\u001b[1;32m    371\u001b[0m         attention_output, att_matrix \u001b[39m=\u001b[39m attention_output\n",
      "File \u001b[0;32m/fsx/home-rudolf/miniconda3/envs/elk2/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/fsx/home-rudolf/miniconda3/envs/elk2/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:293\u001b[0m, in \u001b[0;36mDebertaV2Attention.forward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    285\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    286\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m     rel_embeddings\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    292\u001b[0m ):\n\u001b[0;32m--> 293\u001b[0m     self_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself(\n\u001b[1;32m    294\u001b[0m         hidden_states,\n\u001b[1;32m    295\u001b[0m         attention_mask,\n\u001b[1;32m    296\u001b[0m         output_attentions,\n\u001b[1;32m    297\u001b[0m         query_states\u001b[39m=\u001b[39;49mquery_states,\n\u001b[1;32m    298\u001b[0m         relative_pos\u001b[39m=\u001b[39;49mrelative_pos,\n\u001b[1;32m    299\u001b[0m         rel_embeddings\u001b[39m=\u001b[39;49mrel_embeddings,\n\u001b[1;32m    300\u001b[0m     )\n\u001b[1;32m    301\u001b[0m     \u001b[39mif\u001b[39;00m output_attentions:\n\u001b[1;32m    302\u001b[0m         self_output, att_matrix \u001b[39m=\u001b[39m self_output\n",
      "File \u001b[0;32m/fsx/home-rudolf/miniconda3/envs/elk2/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/fsx/home-rudolf/miniconda3/envs/elk2/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:714\u001b[0m, in \u001b[0;36mDisentangledSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[39mif\u001b[39;00m query_states \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    713\u001b[0m     query_states \u001b[39m=\u001b[39m hidden_states\n\u001b[0;32m--> 714\u001b[0m query_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtranspose_for_scores(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mquery_proj(query_states), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_attention_heads)\n\u001b[1;32m    715\u001b[0m key_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranspose_for_scores(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey_proj(hidden_states), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_attention_heads)\n\u001b[1;32m    716\u001b[0m value_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranspose_for_scores(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalue_proj(hidden_states), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_attention_heads)\n",
      "File \u001b[0;32m/fsx/home-rudolf/miniconda3/envs/elk2/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:672\u001b[0m, in \u001b[0;36mDisentangledSelfAttention.transpose_for_scores\u001b[0;34m(self, x, attention_heads)\u001b[0m\n\u001b[1;32m    670\u001b[0m new_x_shape \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39msize()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m (attention_heads, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    671\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(new_x_shape)\n\u001b[0;32m--> 672\u001b[0m \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39;49mpermute(\u001b[39m0\u001b[39;49m, \u001b[39m2\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m3\u001b[39;49m)\u001b[39m.\u001b[39;49mcontiguous()\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, x\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m), x\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "exgen = extract(extract_config, max_gpus=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elk2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
